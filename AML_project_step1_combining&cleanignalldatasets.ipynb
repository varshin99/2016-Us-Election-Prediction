{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "84FNPYVzYwho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9jLtjPm4DTs"
      },
      "outputs": [],
      "source": [
        "#Importing Libraries\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import emoji"
      ],
      "metadata": {
        "id": "U19DmzvyYtAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aLDlv3Ba6XBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to the Feather file on Google Drive\n",
        "#file_path = '/content/drive/My Drive/output_april.feather'\n",
        "\n",
        "#df = pd.read_feather(file_path)\n",
        "#df_final=pd.read_feather(file_path)"
      ],
      "metadata": {
        "id": "IuNF5dOR6Y2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.listdir('Documents')"
      ],
      "metadata": {
        "id": "gbTr5zckTtYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Replace the file path with your Feather file's path\n",
        "file_path = 'Desktop/output_feb.feather'\n",
        "file_path2 = 'Desktop/output_mar.feather'\n",
        "file_path3= 'Desktop/output_april.feather'\n",
        "file_path4 = 'Desktop/output_may.feather'\n",
        "file_path5 = 'Desktop/output_jun.feather'\n",
        "file_path6 = 'Desktop/output_jul.feather'\n",
        "file_path7 = 'Desktop/output_aug.feather'\n",
        "file_path8 = 'Desktop/output_sept.feather'\n",
        "file_path9 = 'Desktop/output_oct.feather'\n",
        "file_path10 = 'Desktop/output_nov.feather'\n",
        "\n",
        "dffeb = pd.read_feather(file_path)\n",
        "dfmar = pd.read_feather(file_path2)\n",
        "dfapril = pd.read_feather(file_path3)\n",
        "dfmay = pd.read_feather(file_path4)\n",
        "dfjun = pd.read_feather(file_path5)\n",
        "dfjul = pd.read_feather(file_path6)\n",
        "dfaug = pd.read_feather(file_path7)\n",
        "dfsep = pd.read_feather(file_path8)\n",
        "dfoct = pd.read_feather(file_path9)\n",
        "dfnov = pd.read_feather(file_path10)"
      ],
      "metadata": {
        "id": "uHnB5Jjo6Thu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " #Merge all DataFrames into a single DataFrame\n",
        "df_merged = pd.concat([dffeb, dfmar, dfapril, dfmay, dfjun, dfjul, dfaug, dfsep, dfoct, dfnov], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "JTUNCfn4W3mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.head()"
      ],
      "metadata": {
        "id": "6vfYlO5G6a7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7007bcdd-3ca0-4483-9357-e40857ac52a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text             tweetid  \\\n",
              "0  @realDonaldTrump leading pool-boy @marcorubio ...  702946164992114688   \n",
              "1  RT @TheRightScoop: Rush Limbaugh: Ted Cruz fou...  702946165529120772   \n",
              "2  RT @realDonaldTrump: \"@HosierN: @foxnewspoliti...  702946168989466624   \n",
              "3  @realDonaldTrump Mexico isnt gonna pay for the...  702946170176311296   \n",
              "4  @realDonaldTrump He may not have beat you, but...  702946171375980544   \n",
              "\n",
              "       userid                            date               rt_id  rt_userid  \n",
              "0  3291772795  Thu Feb 25 20:00:00 +0000 2016                None       None  \n",
              "1    30080259  Thu Feb 25 20:00:00 +0000 2016  702940427289284609  212708176  \n",
              "2  3702073156  Thu Feb 25 20:00:01 +0000 2016  702680136513155072   25073877  \n",
              "3   236730194  Thu Feb 25 20:00:01 +0000 2016                None       None  \n",
              "4   115698491  Thu Feb 25 20:00:02 +0000 2016                None       None  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>userid</th>\n",
              "      <th>date</th>\n",
              "      <th>rt_id</th>\n",
              "      <th>rt_userid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@realDonaldTrump leading pool-boy @marcorubio ...</td>\n",
              "      <td>702946164992114688</td>\n",
              "      <td>3291772795</td>\n",
              "      <td>Thu Feb 25 20:00:00 +0000 2016</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @TheRightScoop: Rush Limbaugh: Ted Cruz fou...</td>\n",
              "      <td>702946165529120772</td>\n",
              "      <td>30080259</td>\n",
              "      <td>Thu Feb 25 20:00:00 +0000 2016</td>\n",
              "      <td>702940427289284609</td>\n",
              "      <td>212708176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @realDonaldTrump: \"@HosierN: @foxnewspoliti...</td>\n",
              "      <td>702946168989466624</td>\n",
              "      <td>3702073156</td>\n",
              "      <td>Thu Feb 25 20:00:01 +0000 2016</td>\n",
              "      <td>702680136513155072</td>\n",
              "      <td>25073877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@realDonaldTrump Mexico isnt gonna pay for the...</td>\n",
              "      <td>702946170176311296</td>\n",
              "      <td>236730194</td>\n",
              "      <td>Thu Feb 25 20:00:01 +0000 2016</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@realDonaldTrump He may not have beat you, but...</td>\n",
              "      <td>702946171375980544</td>\n",
              "      <td>115698491</td>\n",
              "      <td>Thu Feb 25 20:00:02 +0000 2016</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_userid_count = df_merged['userid'].nunique()\n",
        "print(unique_userid_count)\n",
        "# there are 852278 unique users in this dataset."
      ],
      "metadata": {
        "id": "DMY6JRuv6cxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2694bf47-53bf-433a-ee0e-f1392910d27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6719355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.info()"
      ],
      "metadata": {
        "id": "B00FiHe17gab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dca5c5f-0675-497b-b95e-2c0cb98bbe31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74231650 entries, 0 to 74231649\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Dtype \n",
            "---  ------     ----- \n",
            " 0   text       object\n",
            " 1   tweetid    object\n",
            " 2   userid     object\n",
            " 3   date       object\n",
            " 4   rt_id      object\n",
            " 5   rt_userid  object\n",
            "dtypes: object(6)\n",
            "memory usage: 3.3+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_merged)"
      ],
      "metadata": {
        "id": "Qz8YwuuXBtOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2cc688f-45e0-4ec1-8574-f2aa458bc986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74231650"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_dataframe(df):\n",
        "    \"\"\"\n",
        "    Analyzes a DataFrame for null values and counts unique tweet IDs used in 'rt_id'.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The DataFrame to analyze.\n",
        "\n",
        "    Returns:\n",
        "    str: A summary of the analysis.\n",
        "    \"\"\"\n",
        "    # Check for null values in the DataFrame\n",
        "    null_counts = df.isnull().sum()\n",
        "\n",
        "    # Count how many tweet IDs are used in rt_id\n",
        "    tweet_ids_in_rt_id = df['rt_id'].str.extractall(r'(\\d+)')[0].nunique()\n",
        "\n",
        "    summary = \"Null Value Counts:\\n\" + str(null_counts) + \"\\n\\nNumber of tweet IDs used in rt_id: \" + str(tweet_ids_in_rt_id)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "5UwQp5UvO1Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_dataframe(df_merged)"
      ],
      "metadata": {
        "id": "C2prodNGO2gT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a70ebb4-9b3f-42b0-ee8c-f4d06e4e0a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Null Value Counts:\\ntext                0\\ntweetid             0\\nuserid              0\\ndate                0\\nrt_id        23255387\\nrt_userid    23255387\\ndtype: int64\\n\\nNumber of tweet IDs used in rt_id: 69412'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_retweet_info(df):\n",
        "    \"\"\"\n",
        "    Adds a retweet count column to the DataFrame and imputes the 'rt_id' and 'rt_userid' columns.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The DataFrame to process.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The updated DataFrame with retweet information.\n",
        "    \"\"\"\n",
        "    # Count how many times each tweet ID appears in the rt_id column\n",
        "    retweet_counts = df['rt_id'].value_counts()\n",
        "\n",
        "    # Map the count to the tweetid column\n",
        "    df['retweet_count'] = df['tweetid'].map(retweet_counts).fillna(0)\n",
        "\n",
        "    # Impute 'rt_id' and 'rt_userid' columns based on the retweet count\n",
        "    df['rt_id'] = df.apply(lambda x: \"there are retweets\" if x['retweet_count'] > 0 else \"no retweets\", axis=1)\n",
        "    df['rt_userid'] = df.apply(lambda x: \"there are retweets\" if x['retweet_count'] > 0 else \"no retweets\", axis=1)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "8frzxDXuMwge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling funcction\n",
        "updated_df = add_retweet_info(df_merged)\n"
      ],
      "metadata": {
        "id": "dMaAIxXOMxiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_userid_count = updated_df['userid'].nunique()\n",
        "print(unique_userid_count)\n",
        "# there are  unique users in this dataset."
      ],
      "metadata": {
        "id": "EGK711-wQnGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16c0364-c005-4649-d6a8-27019231a50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6719355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = updated_df.loc[updated_df['tweetid'] == '699968804311470080', ['text', 'tweetid','userid','date','rt_id','rt_userid','retweet_count']]\n",
        "selected_data.head(100)\n",
        "#Once we gone through all the null values, we relaized that we cant remove all the nuill values becuse those are tweets that are not retweed by anyone\n",
        "#these are still usefull the analysis, so we are goine impute with \"No_one_retweeted\" on the both columns\n"
      ],
      "metadata": {
        "id": "olZ_OYqX6gun",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "6e931b10-bc2c-47fb-c20c-015d540f0273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text  \\\n",
              "3671900  .@FoxNews is so biased it is disgusting. They ...   \n",
              "\n",
              "                    tweetid    userid                            date  \\\n",
              "3671900  699968804311470080  25073877  Wed Feb 17 14:49:02 +0000 2016   \n",
              "\n",
              "                      rt_id           rt_userid  retweet_count  \n",
              "3671900  there are retweets  there are retweets        23870.0  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>userid</th>\n",
              "      <th>date</th>\n",
              "      <th>rt_id</th>\n",
              "      <th>rt_userid</th>\n",
              "      <th>retweet_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3671900</th>\n",
              "      <td>.@FoxNews is so biased it is disgusting. They ...</td>\n",
              "      <td>699968804311470080</td>\n",
              "      <td>25073877</td>\n",
              "      <td>Wed Feb 17 14:49:02 +0000 2016</td>\n",
              "      <td>there are retweets</td>\n",
              "      <td>there are retweets</td>\n",
              "      <td>23870.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = updated_df[updated_df.duplicated()]\n",
        "duplicates.head()\n",
        "# The following dataset contians all the duplicates in df dataset\n",
        "duplicates.count()\n",
        "# so there are  duplicate in the dataset so we are gone remove these duplicates from the dataset"
      ],
      "metadata": {
        "id": "aUmDoMIaX5SO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8b5272-bf91-4322-98d7-4c8d02adfaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text             847129\n",
              "tweetid          847129\n",
              "userid           847129\n",
              "date             847129\n",
              "rt_id            847129\n",
              "rt_userid        847129\n",
              "retweet_count    847129\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = updated_df.drop_duplicates()"
      ],
      "metadata": {
        "id": "7SHR86a2X7a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = filtered_df[filtered_df.duplicated()]\n",
        "duplicates.head()\n",
        "# The following dataset contians all the duplicates in df dataset\n",
        "duplicates.count()\n",
        "# so there are  duplicate in the dataset so we are gone remove these duplicates from the dataset"
      ],
      "metadata": {
        "id": "gHpvZcfyX-a-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c87aa1b-19bd-48da-fed8-e137d07ada6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text             0\n",
              "tweetid          0\n",
              "userid           0\n",
              "date             0\n",
              "rt_id            0\n",
              "rt_userid        0\n",
              "retweet_count    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgKmRKGcUJkE",
        "outputId": "f0b19364-7bfc-44ef-8240-b83e6d2eb575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73384521"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_df = pd.DataFrame(filtered_df)\n",
        "# Convert the 'date' column into datetime format\n",
        "filtered_df['datetime'] = pd.to_datetime(filtered_df['date'], format='%a %b %d %H:%M:%S +0000 %Y')\n",
        "# Extract individual components\n",
        "filtered_df['day_of_week'] = filtered_df['datetime'].dt.strftime('%A')\n",
        "filtered_df['month'] = filtered_df['datetime'].dt.strftime('%B')\n",
        "filtered_df['day'] = filtered_df['datetime'].dt.day\n",
        "filtered_df['hour'] = filtered_df['datetime'].dt.hour\n",
        "filtered_df['minute'] = filtered_df['datetime'].dt.minute\n",
        "filtered_df['second'] = filtered_df['datetime'].dt.second\n",
        "filtered_df['year'] = filtered_df['datetime'].dt.year\n",
        "filtered_df['timezone'] = filtered_df['date'].str.split(' ').str[4]\n",
        "# Drop the original 'date' column and 'datetime' column if not needed\n",
        "#filtered_df = filtered_df.drop(columns=['date', 'datetime'])"
      ],
      "metadata": {
        "id": "CsLtnMuNYAcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a tweet contains a link\n",
        "filtered_df['contains_link'] = filtered_df['text'].str.contains('http://|https://|www\\.')\n",
        "\n",
        "# Count the tweets with and without links\n",
        "link_counts = filtered_df['contains_link'].value_counts()\n",
        "\n",
        "link_counts\n"
      ],
      "metadata": {
        "id": "2Wbczv78YTJb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0e7ca7-23ef-4738-8819-6dee519cfe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "contains_link\n",
              "False    50020967\n",
              "True     23363554\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_emojis(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
        "                           u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "                           u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "                           u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                           u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "                           u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                           u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.findall(text)\n",
        "\n",
        "filtered_df['emojis'] = filtered_df['text'].apply(extract_emojis)\n",
        "emoji_counts = filtered_df['emojis'].explode().value_counts()"
      ],
      "metadata": {
        "id": "93nMdybBYXa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df['tweet_length'] = filtered_df['text'].apply(len)"
      ],
      "metadata": {
        "id": "sGXD8T17YbMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the index of the filtered DataFrame if needed\n",
        "filtered_df.reset_index(drop=True, inplace=True)\n",
        "# Saving the DataFrame to a Feather file\n",
        "filtered_df.to_feather('df_all_merged_data_sentimentanalysis.feather')"
      ],
      "metadata": {
        "id": "BHNDQxcJDMVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rt_count = updated_df['text'].str.startswith('RT').sum()\n",
        "print(\"Number of tweets starting with 'RT':\", rt_count)"
      ],
      "metadata": {
        "id": "JVxAjo_t8u54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f433b78c-4b95-463e-ab9c-1a1947301bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets starting with 'RT': 50976326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to drop rows where tweets start with \"RT\"\n",
        "filtered_df = filtered_df[~filtered_df['text'].str.startswith('RT')]\n",
        "# Reset the index of the filtered DataFrame if needed\n",
        "filtered_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Qa_lap7YBcM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filtered_df = updated_df\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "xnQOgw4VBlOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "bb2ea902-5637-4345-ed43-6113accfb71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text             tweetid  \\\n",
              "0  @realDonaldTrump leading pool-boy @marcorubio ...  702946164992114688   \n",
              "1  @realDonaldTrump Mexico isnt gonna pay for the...  702946170176311296   \n",
              "2  @realDonaldTrump He may not have beat you, but...  702946171375980544   \n",
              "3  @tedcruz Don't allow Trump say LIAR when He's ...  702946181920514049   \n",
              "4  @realDonaldTrump You know white people all com...  702946189533179904   \n",
              "\n",
              "       userid                            date        rt_id    rt_userid  \\\n",
              "0  3291772795  Thu Feb 25 20:00:00 +0000 2016  no retweets  no retweets   \n",
              "1   236730194  Thu Feb 25 20:00:01 +0000 2016  no retweets  no retweets   \n",
              "2   115698491  Thu Feb 25 20:00:02 +0000 2016  no retweets  no retweets   \n",
              "3   523773033  Thu Feb 25 20:00:04 +0000 2016  no retweets  no retweets   \n",
              "4    61365816  Thu Feb 25 20:00:06 +0000 2016  no retweets  no retweets   \n",
              "\n",
              "   retweet_count            datetime day_of_week     month  day  hour  minute  \\\n",
              "0            0.0 2016-02-25 20:00:00    Thursday  February   25    20       0   \n",
              "1            0.0 2016-02-25 20:00:01    Thursday  February   25    20       0   \n",
              "2            0.0 2016-02-25 20:00:02    Thursday  February   25    20       0   \n",
              "3            0.0 2016-02-25 20:00:04    Thursday  February   25    20       0   \n",
              "4            0.0 2016-02-25 20:00:06    Thursday  February   25    20       0   \n",
              "\n",
              "   second  year timezone  contains_link emojis  tweet_length  \n",
              "0       0  2016    +0000           True     []           140  \n",
              "1       1  2016    +0000          False     []           137  \n",
              "2       2  2016    +0000          False     []            69  \n",
              "3       4  2016    +0000          False     []           139  \n",
              "4       6  2016    +0000          False     []            85  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>userid</th>\n",
              "      <th>date</th>\n",
              "      <th>rt_id</th>\n",
              "      <th>rt_userid</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>datetime</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>year</th>\n",
              "      <th>timezone</th>\n",
              "      <th>contains_link</th>\n",
              "      <th>emojis</th>\n",
              "      <th>tweet_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@realDonaldTrump leading pool-boy @marcorubio ...</td>\n",
              "      <td>702946164992114688</td>\n",
              "      <td>3291772795</td>\n",
              "      <td>Thu Feb 25 20:00:00 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:00</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@realDonaldTrump Mexico isnt gonna pay for the...</td>\n",
              "      <td>702946170176311296</td>\n",
              "      <td>236730194</td>\n",
              "      <td>Thu Feb 25 20:00:01 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:01</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@realDonaldTrump He may not have beat you, but...</td>\n",
              "      <td>702946171375980544</td>\n",
              "      <td>115698491</td>\n",
              "      <td>Thu Feb 25 20:00:02 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:02</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@tedcruz Don't allow Trump say LIAR when He's ...</td>\n",
              "      <td>702946181920514049</td>\n",
              "      <td>523773033</td>\n",
              "      <td>Thu Feb 25 20:00:04 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:04</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@realDonaldTrump You know white people all com...</td>\n",
              "      <td>702946189533179904</td>\n",
              "      <td>61365816</td>\n",
              "      <td>Thu Feb 25 20:00:06 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:06</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_df)"
      ],
      "metadata": {
        "id": "ahAivPoq87Gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5eda87-5db2-46fc-f21b-119bf0a37717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23006164"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_dataframe(filtered_df)"
      ],
      "metadata": {
        "id": "NyOlZLPB8AX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde354d-c8e1-4290-d157-6899d7144281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Null Value Counts:\\ntext             0\\ntweetid          0\\nuserid           0\\ndate             0\\nrt_id            0\\nrt_userid        0\\nretweet_count    0\\ndatetime         0\\nday_of_week      0\\nmonth            0\\nday              0\\nhour             0\\nminute           0\\nsecond           0\\nyear             0\\ntimezone         0\\ncontains_link    0\\nemojis           0\\ntweet_length     0\\ndtype: int64\\n\\nNumber of tweet IDs used in rt_id: 0'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have the necessary NLTK data downloaded\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def char_is_emoji(character):\n",
        "    #en_emoji = emoji.UNICODE_EMOJI.get(\"en\")\n",
        "    #return character[0] in emoji.UNICODE_EMOJI_ENGLISH\n",
        "    return emoji.is_emoji(character[0])  #check out the API for emoji here: https://carpedm20.github.io/emoji/docs/api.html#\n",
        "\n",
        "# Let's test it with a couple of examples\n",
        "# Now we will add a layer to test every character in a string to see if it\n",
        "# is an emoji.\n",
        "def text_has_emoji(text):\n",
        "    for character in text:\n",
        "        if char_is_emoji(character):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "text_has_emoji(\"Python is go!\"), text_has_emoji(\"Python is go ðŸ‘\")"
      ],
      "metadata": {
        "id": "E5T50-LeZBQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae8a5c8c-abee-406f-a515-ffafc88780bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "slangs = {\"afap\":\"as far as possible\", \"aab\":\"average at best\", \"aak\":\"alive and kicking\", \"aamof\":\"as a matter of fact\", \"aap\":\"always a pleasure\", \"aar\":\"at any rate\", \"aayf\":\"as always: your friend\", \"abd\":\"already been done\", \"admin\":\"administrator\", \"adn\":\"any day now\", \"aeae\":\"and ever and ever\", \"aeap\":\"as early as possible\", \"afaiac\":\"as far as i am concerned\", \"afaic\":\"as far as i am concerned\", \"afaics\":\"as far as i can see\", \"afaict\":\"as far as i can tell\", \"afaik\":\"as far as i know\", \"afair\":\"as far as i remember\", \"afc\":\"always from computer\", \"agw\":\"all going well\", \"afd\":\"all fucking day\", \"aft\":\"about fucking time\", \"b4\":\"before\", \"bb\":\"bye bye\", \"bbiab\":\"be back in a bit\", \"bbl\":\"be back later\", \"bbs\":\"be back soon\", \"bd\":\"big deal\", \"brb\":\"be right back\", \"brt\":\"be right there\", \"btw\":\"by the way\", \"cu\":\"see you\", \"cul\":\"see you later\", \"cuz\":\"because\", \"cya\":\"see you\", \"da\":\"the\", \"dat\":\"that\", \"der\":\"there\", \"dunno\":\"do not know\", \"fwiw\":\"for what it is worth\", \"fyi\":\"for your information\", \"g2g\":\"got to go\", \"gtg\":\"got to go\", \"gal\":\"get a life\", \"gfy\":\"good for you\", \"gonna\":\"going to\", \"icydk\":\"in case you do not know\", \"idgi\":\"i do not get it\", \"idk\":\"i do not know\", \"ily\":\"i love you\", \"ilu\":\"i love you\", \"imho\":\"in my honest opinion\", \"imo\":\"in my opinion\", \"irl\":\"in real life\", \"jj\":\"just joking\", \"jk\":\"just kidding\", \"k\":\"okay\", \"kk\":\"ok cool\", \"l8r\":\"later\", \"lmao\":\"laughing my ass off\", \"lmfao\":\"laughing my fucking ass off\", \"lol\":\"laughing out loud\", \"myob\":\"mind your own business\", \"noyb\":\"none of your business\", \"np\":\"no problem\", \"nsfw\":\"not safe for work\", \"nvm\":\"never mind\", \"omg\":\"oh my god\", \"pic\":\"picture\", \"ot\":\"off topic\", \"pix\":\"pictures\", \"plz\":\"please\", \"pls\":\"please\", \"ppl\":\"people\", \"rofl\":\"rolling on the floor laughing\", \"roflmao\":\"rolling on the floor laughing my ass off\", \"roflmaol\":\"rolling on the floor laughing my ass out loud\", \"smh\":\"shaking my head\", \"thnx\":\"thanks\", \"tho\":\"though\", \"tia\":\"thanks in advance\", \"ttyl\":\"talk to you later\", \"ttyt\":\"talk to you tomorrow\", \"ty\":\"thank you\", \"u\":\"you\", \"w8\":\"wait\", \"wanna\":\"want to\", \"wb\":\"welcome back\", \"wd\":\"well done\", \"im\":\"i am\", \"you've\":\"you have\", \"how'd\":\"how did\", \"i'm\":\"i am\", \"n't\":\"not\", \"we're\":\"we are\", \"you're\":\"you are\"}\n",
        "negated = {\"weren't\":\"were not\", \"hadn't\": \"had not\", \"wouldn't\": \"would not\", \"mustn't\": \"must not\", \"aren't\": \"are not\", \"wasn't\": \"was not\", \"couldn't\": \"could not\", \"shan't\": \"shall not\", \"haven't\": \"have not\", \"mightn't\": \"might not\", \"doesn't\": \"does not\", \"needn't\": \"need not\", \"don't\": \"do not\", \"isn't\": \"is not\", \"hasn't\": \"has not\", \"doesn't\": \"does not\", \"didn't\": \"did not\", \"won't\": \"will not\", \"oughtn't\": \"ought not\", \"shouldn't\": \"should not\", \"cannot\": \"can not\", \"can't\": \"can not\"}\n",
        "emoticons = [\"[: )\", \":-]\", \":-3\", \":->\", \"8-)\", \":-}\", \":)\", \":]\", \":3\", \":>\", \"8)\", \":}\", \":o)\", \":c)\", \":^)\", \"=]\", \"=)\", \":-))\", \": D\", \"8 D\", \"x D\", \"X D\", \":D\", \"8D\", \"xD\", \"XD\", \"=D\", \"=3\", \"B^D\", \":-*\", \":*\", \":Ã—'\", \"; )\", \"*-)\", \"; ]\", \";)\", \"*)\", \";]\", \";^)\", \": ,\", \";D\", \"<3\", \"(:\", \": (\", \": c\", \": <\", \": [\", \":(\", \":c\", \":<\", \":[\", \":-||\", \">:[\", \":{\", \":@\", \">:(\", \":' (\", \":'(\", \"D ':\", \"D:<\", \"D:\", \"D8\", \"D;\", \"D=\", \"DX\", \": O\", \": o\", \":O\", \":o\", \":-0\", \"8 0\", \">:O\"]\n",
        "\n",
        "type(slangs), type(negated), type(emoticons)"
      ],
      "metadata": {
        "id": "-ODx9wxlZFnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d435c96-b472-460e-e810-70448a329223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict, dict, list)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next we will use our emoji finder to clean up the texts of a list of tweets.\n",
        "# This function tokenizes the input and does many different transformations\n",
        "# to the text and the tokens.\n",
        "\n",
        "\n",
        "\n",
        "def clean_tweets(text):\n",
        "        cleaned_tweets ='' # This will be our return list\n",
        "        hash_emos = [] # This is an overall list of emoticons and emojis\n",
        "\n",
        "    # Loop over the full list of texts provided\n",
        "          # Simulating a delay\n",
        "        hash_emo = [] # Initialize an empty list for this one text\n",
        "\n",
        "        # These make substitutions of short tags in place of repeating\n",
        "        # exclamation marks and/or question marks.\n",
        "        text = re.sub('(!){2,}', ' <!repeat> ', text)\n",
        "        text = re.sub('(\\?){2,}', ' <?repeat> ', text)\n",
        "\n",
        "        # Tokenize using tweet tokenizer: This will treat each emoji as\n",
        "        # its own token.\n",
        "        tokenizer = nltk.tokenize.TweetTokenizer(strip_handles=False, reduce_len=True)\n",
        "        tokens = tokenizer.tokenize(text.lower())\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "        # Emojis and emoticons\n",
        "        if text_has_emoji(text): # Examine the untokenized text\n",
        "            temp = [] # Make temporary storage for the modified tokens\n",
        "            for tok in tokens: # Cycle through each token in this text\n",
        "                # If the token is an emoji, look up the equivalent\n",
        "                # plain text placeholder.\n",
        "                if char_is_emoji(tok):\n",
        "                    temp.append(emoji.demojize(tok))\n",
        "                elif tok in emoticons:\n",
        "                    temp.append(tok)\n",
        "                else:\n",
        "                    temp.append(tok)\n",
        "            tokens = temp\n",
        "\n",
        "        # Hashtags\n",
        "        temp = []\n",
        "        for word in tokens:\n",
        "            if '#' in word: # Do a simple substitution using the empty string\n",
        "                word = word.replace('#','')\n",
        "                temp.append(word)\n",
        "            else:\n",
        "                temp.append(word)\n",
        "        tokens = temp\n",
        "\n",
        "        # Replace slangs and negated words\n",
        "        temp = []\n",
        "        for word in tokens:\n",
        "            if word in slangs:\n",
        "                temp += slangs[word].split()\n",
        "\n",
        "            elif word in negated:\n",
        "                temp += negated[word].split()\n",
        "\n",
        "            else:\n",
        "                temp.append(word)\n",
        "\n",
        "        tokens = temp\n",
        "\n",
        "        # Replace user names\n",
        "        tokens = ['<user>'  if '@' in word else word for word in tokens]\n",
        "\n",
        "        #Replace numbers\n",
        "        tokens = ['<number>' if word.isdigit() else word for word in tokens]\n",
        "\n",
        "        # Remove urls\n",
        "        tokens = ['' if 'http' in word else word for word in tokens]\n",
        "\n",
        "        # Lemmatize\n",
        "        #tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "        # Remove stop words\n",
        "        tokens = [word for word in tokens if word not in nltk.corpus.stopwords.words('english')]\n",
        "\n",
        "        # Remove tokens having length 1\n",
        "        tokens = [word for word in tokens if word != '' and len(word) > 1]\n",
        "\n",
        "        cleaned_tweets=tokens\n",
        "\n",
        "        return ' '.join(cleaned_tweets)"
      ],
      "metadata": {
        "id": "VlZDOsQWZHqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_1=filtered_df\n",
        "#start_time = time.time()\n",
        "df_final_1[\"clean_data\"]=df_final_1['text'].apply(clean_tweets)\n",
        "\n",
        "#end_time = time.time()  # End time\n",
        "#total_time = end_time - start_time\n",
        "\n",
        "#print(f\"The function took {total_time/60} seconds to run.\")"
      ],
      "metadata": {
        "id": "eaAvt5-dZKK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_1.info()"
      ],
      "metadata": {
        "id": "v5zmN9A1Td1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda52919-b120-4e3b-9f0e-00df9d658599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23006164 entries, 0 to 23006163\n",
            "Data columns (total 20 columns):\n",
            " #   Column         Dtype         \n",
            "---  ------         -----         \n",
            " 0   text           object        \n",
            " 1   tweetid        object        \n",
            " 2   userid         object        \n",
            " 3   date           object        \n",
            " 4   rt_id          object        \n",
            " 5   rt_userid      object        \n",
            " 6   retweet_count  float64       \n",
            " 7   datetime       datetime64[ns]\n",
            " 8   day_of_week    object        \n",
            " 9   month          object        \n",
            " 10  day            int32         \n",
            " 11  hour           int32         \n",
            " 12  minute         int32         \n",
            " 13  second         int32         \n",
            " 14  year           int32         \n",
            " 15  timezone       object        \n",
            " 16  contains_link  bool          \n",
            " 17  emojis         object        \n",
            " 18  tweet_length   int64         \n",
            " 19  clean_data     object        \n",
            "dtypes: bool(1), datetime64[ns](1), float64(1), int32(5), int64(1), object(11)\n",
            "memory usage: 2.8+ GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_1.head()"
      ],
      "metadata": {
        "id": "VFF5DHlLTf4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c101c645-46b7-4d35-a65a-99e37ea66c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text             tweetid  \\\n",
              "0  @realDonaldTrump leading pool-boy @marcorubio ...  702946164992114688   \n",
              "1  @realDonaldTrump Mexico isnt gonna pay for the...  702946170176311296   \n",
              "2  @realDonaldTrump He may not have beat you, but...  702946171375980544   \n",
              "3  @tedcruz Don't allow Trump say LIAR when He's ...  702946181920514049   \n",
              "4  @realDonaldTrump You know white people all com...  702946189533179904   \n",
              "\n",
              "       userid                            date        rt_id    rt_userid  \\\n",
              "0  3291772795  Thu Feb 25 20:00:00 +0000 2016  no retweets  no retweets   \n",
              "1   236730194  Thu Feb 25 20:00:01 +0000 2016  no retweets  no retweets   \n",
              "2   115698491  Thu Feb 25 20:00:02 +0000 2016  no retweets  no retweets   \n",
              "3   523773033  Thu Feb 25 20:00:04 +0000 2016  no retweets  no retweets   \n",
              "4    61365816  Thu Feb 25 20:00:06 +0000 2016  no retweets  no retweets   \n",
              "\n",
              "   retweet_count            datetime day_of_week     month  day  hour  minute  \\\n",
              "0            0.0 2016-02-25 20:00:00    Thursday  February   25    20       0   \n",
              "1            0.0 2016-02-25 20:00:01    Thursday  February   25    20       0   \n",
              "2            0.0 2016-02-25 20:00:02    Thursday  February   25    20       0   \n",
              "3            0.0 2016-02-25 20:00:04    Thursday  February   25    20       0   \n",
              "4            0.0 2016-02-25 20:00:06    Thursday  February   25    20       0   \n",
              "\n",
              "   second  year timezone  contains_link emojis  tweet_length  \\\n",
              "0       0  2016    +0000           True     []           140   \n",
              "1       1  2016    +0000          False     []           137   \n",
              "2       2  2016    +0000          False     []            69   \n",
              "3       4  2016    +0000          False     []           139   \n",
              "4       6  2016    +0000          False     []            85   \n",
              "\n",
              "                                          clean_data  \n",
              "0  <user> leading pool-boy <user> home state flor...  \n",
              "1  <user> mexico isnt going pay fucking wall ... ...  \n",
              "2                        <user> may beat still loser  \n",
              "3  <user> allow trump say liar he's real devious ...  \n",
              "4  <user> know white people come native african b...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>userid</th>\n",
              "      <th>date</th>\n",
              "      <th>rt_id</th>\n",
              "      <th>rt_userid</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>datetime</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>second</th>\n",
              "      <th>year</th>\n",
              "      <th>timezone</th>\n",
              "      <th>contains_link</th>\n",
              "      <th>emojis</th>\n",
              "      <th>tweet_length</th>\n",
              "      <th>clean_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@realDonaldTrump leading pool-boy @marcorubio ...</td>\n",
              "      <td>702946164992114688</td>\n",
              "      <td>3291772795</td>\n",
              "      <td>Thu Feb 25 20:00:00 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:00</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>True</td>\n",
              "      <td>[]</td>\n",
              "      <td>140</td>\n",
              "      <td>&lt;user&gt; leading pool-boy &lt;user&gt; home state flor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@realDonaldTrump Mexico isnt gonna pay for the...</td>\n",
              "      <td>702946170176311296</td>\n",
              "      <td>236730194</td>\n",
              "      <td>Thu Feb 25 20:00:01 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:01</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>137</td>\n",
              "      <td>&lt;user&gt; mexico isnt going pay fucking wall ... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@realDonaldTrump He may not have beat you, but...</td>\n",
              "      <td>702946171375980544</td>\n",
              "      <td>115698491</td>\n",
              "      <td>Thu Feb 25 20:00:02 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:02</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>69</td>\n",
              "      <td>&lt;user&gt; may beat still loser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@tedcruz Don't allow Trump say LIAR when He's ...</td>\n",
              "      <td>702946181920514049</td>\n",
              "      <td>523773033</td>\n",
              "      <td>Thu Feb 25 20:00:04 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:04</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>139</td>\n",
              "      <td>&lt;user&gt; allow trump say liar he's real devious ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@realDonaldTrump You know white people all com...</td>\n",
              "      <td>702946189533179904</td>\n",
              "      <td>61365816</td>\n",
              "      <td>Thu Feb 25 20:00:06 +0000 2016</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>no retweets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2016-02-25 20:00:06</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>February</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2016</td>\n",
              "      <td>+0000</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>85</td>\n",
              "      <td>&lt;user&gt; know white people come native african b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetting the index of the DataFrame\n",
        "df_final_1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Saving the DataFrame to a Feather file\n",
        "df_final_1.to_feather('df_all_merged&filtered_cleaned_data_topiclabels.feather')\n"
      ],
      "metadata": {
        "id": "MMRHfXw7XMSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_final_1)"
      ],
      "metadata": {
        "id": "Ud6oIPbbT8o3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a843db-f664-4058-e915-c4402235f386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23006164"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}